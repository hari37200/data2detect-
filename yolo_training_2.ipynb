{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d4675a-e88d-42c5-9701-3aebd9d7098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing train: 100%|██████████| 426/426 [00:00<00:00, 437.28it/s]\n",
      "Preparing val: 100%|██████████| 122/122 [00:00<00:00, 454.22it/s]\n",
      "Preparing test: 100%|██████████| 61/61 [00:00<00:00, 440.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset conversion complete for YOLOv8 (1-class detection only).\n"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil, tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "base_dir = r'C:\\Users\\aswin\\Downloads\\Yolo_test_dataset'\n",
    "img_dir = os.path.join(base_dir, 'TsignDet Test Database', 'test_image')\n",
    "ann_dir = os.path.join(base_dir, 'TsignDet Test Database Annotation', 'lable')\n",
    "\n",
    "output_dir = r'C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset'\n",
    "img_out_dir = os.path.join(output_dir, 'images')\n",
    "label_out_dir = os.path.join(output_dir, 'labels')\n",
    "\n",
    "# Step 1: Collect all valid image-label pairs\n",
    "images = glob.glob(os.path.join(img_dir, '*.jpg'))\n",
    "pairs = [(img, os.path.join(ann_dir, os.path.basename(img).replace('.jpg', '.txt')))\n",
    "         for img in images if os.path.exists(os.path.join(ann_dir, os.path.basename(img).replace('.jpg', '.txt')))]\n",
    "\n",
    "# Step 2: Split into train/val/test\n",
    "train, temp = train_test_split(pairs, test_size=0.3, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=1/3, random_state=42)\n",
    "\n",
    "splits = {'train': train, 'val': val, 'test': test}\n",
    "\n",
    "# Step 3: Conversion function (polygon to YOLO box)\n",
    "def convert_polygon_to_yolo(poly_line, img_w=640, img_h=480):\n",
    "    nums = list(map(int, poly_line.strip().split(',')))\n",
    "    xs = nums[::2]\n",
    "    ys = nums[1::2]\n",
    "    x_min, x_max = min(xs), max(xs)\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "    x_c = (x_min + x_max) / 2 / img_w\n",
    "    y_c = (y_min + y_max) / 2 / img_h\n",
    "    w   = (x_max - x_min) / img_w\n",
    "    h   = (y_max - y_min) / img_h\n",
    "    return f\"0 {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\"\n",
    "\n",
    "# Step 4: Copy + Convert\n",
    "for split, data in splits.items():\n",
    "    img_dst = os.path.join(img_out_dir, split)\n",
    "    lbl_dst = os.path.join(label_out_dir, split)\n",
    "    os.makedirs(img_dst, exist_ok=True)\n",
    "    os.makedirs(lbl_dst, exist_ok=True)\n",
    "\n",
    "    for img_path, ann_path in tqdm.tqdm(data, desc=f'Preparing {split}'):\n",
    "        fname = os.path.basename(img_path)\n",
    "        shutil.copy(img_path, os.path.join(img_dst, fname))\n",
    "\n",
    "        with open(ann_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        yolo_lines = []\n",
    "        for line in lines:\n",
    "            if ',' in line:\n",
    "                try:\n",
    "                    yolo_lines.append(convert_polygon_to_yolo(line))\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Skipping bad line in {ann_path}: {line.strip()}\")\n",
    "\n",
    "        with open(os.path.join(lbl_dst, fname.replace('.jpg', '.txt')), 'w') as out_f:\n",
    "            out_f.write('\\n'.join(yolo_lines))\n",
    "\n",
    "print('✅ Dataset conversion complete for YOLOv8 (1-class detection only).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1f4915-09e3-4674-9ee9-69b91adb3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161  Python-3.12.3 torch-2.7.1+cpu CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\tsdd.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.2 ms, read: 304.0149.7 MB/s, size: 960.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\train... 1403 images, 468 backgrounds, 44 corrupt: 100%|██████████| 1871/1871 [00:04<00:00, 455.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd (34).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.2086      3.2854      3.4383      3.2854      3.7391      3.2635]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd (36).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.9742      1.6073]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1000.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4719      1.3844]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1003.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.7984      1.1323]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1011.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1352      1.5615      1.6383      1.5208      2.1172      1.4865      2.5766      1.4937      3.0734      1.4531]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1016.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.3164      1.0646      2.6813      1.1594      2.0328      1.2958      1.2961      1.4792      1.6156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1017.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2177      3.4594      1.7687      2.6609      1.5542       2.007      1.4427      1.3703      1.2271]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1021.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7602      1.8708      2.0719       1.874      2.1969      1.8469]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1025.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5969      1.3906      2.1656      1.2177      2.5812      1.0917]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1027.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5945      1.5042      2.2172      1.6354         2.6       1.749]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_202.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2609]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_646.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1914      2.2039      1.6771      2.2297      2.6156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_660.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.6172      1.7656]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_661.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1914      1.6635      1.5672]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_667.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4414      1.8979      2.0867      1.8135      2.7477       1.799      3.4562      1.7615]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_677.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4898      2.0135]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_678.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1172      1.8292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_681.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2578      1.6938      2.3031      1.9594       2.275      2.2385]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_687.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9922      1.6844      2.0586       2.249       2.018      1.1625]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_689.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.043      1.0646      2.1195       1.599       2.207      2.0583]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_691.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0766       1.401      2.1047      1.6802]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_696.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.018      1.3365      2.0641      2.3021      1.0958]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_704.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0586       1.575      1.1208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_730.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0664      1.5229      2.0234      1.8135      1.9875      2.0844]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_749.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9289      2.9562]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_755.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1937      1.4552      2.1883      1.6771      2.1633      1.8479]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_802.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9727      1.3229      1.9469        1.85]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_806.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0047      1.5104      2.0531      2.0885]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_836.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.525      2.7823]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_845.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.3625      2.0271      2.3805      2.1865]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_848.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5766      2.7344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_853.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5719      2.5302      2.5812      2.7552      2.6273      3.0448]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_858.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5055      3.1021      2.5102      3.2344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_885.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4867       1.976      1.8547      1.9865      2.1984      1.9323]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_888.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5203      1.5781      1.9469      1.4688      2.2578      1.3292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_898.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.6664      2.8031      1.8898      1.6562]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_957.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4156      2.2938      1.7135      2.1477      2.4896]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_958.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9156      2.0586       1.551      2.2422      2.3198]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1039      1.5604       2.143      1.8094      2.1883      2.0708]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_964.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2297      1.6531]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_986.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7039      1.8708      1.8953      1.8062      2.0508       1.775      2.2445      1.7271]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_993.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0617      1.4312      2.0766      1.7083       2.082       1.976]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_994.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2445      1.5812      2.1992      1.8094      2.2195      2.1156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_995.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0539      1.4698      2.1195      1.7687      2.1578      2.0135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 432.239.3 MB/s, size: 137.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\val... 122 images, 0 backgrounds, 2 corrupt: 100%|██████████| 122/122 [00:00<00:00, 410.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\val\\tsd (33).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.2008      3.6531]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\val\\tsd (35).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.7891      4.0146      3.0109      3.9875      3.2133      4.0583]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\aswin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "       1/10         0G      2.355      4.021      1.591          1        640: 100%|██████████| 115/115 [13:10<00:00,  6.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:13<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.379      0.327      0.261     0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      2.418      2.986      1.601          2        640: 100%|██████████| 115/115 [12:01<00:00,  6.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:11<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.327       0.35      0.247     0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      2.362      2.571        1.6          5        640: 100%|██████████| 115/115 [11:41<00:00,  6.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:10<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.447      0.378      0.318      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      2.341      2.396      1.595          3        640: 100%|██████████| 115/115 [11:41<00:00,  6.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:10<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.445       0.41      0.334      0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      2.294      2.185      1.565          4        640: 100%|██████████| 115/115 [11:36<00:00,  6.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:11<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.442      0.399      0.362      0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      2.268      2.156      1.557          5        640: 100%|██████████| 115/115 [11:43<00:00,  6.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:10<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.513      0.404      0.384      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      2.235      2.057      1.538          7        640: 100%|██████████| 115/115 [11:44<00:00,  6.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:10<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.484      0.414      0.388      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      2.236      1.996      1.504          4        640: 100%|██████████| 115/115 [15:45<00:00,  8.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.431      0.458      0.414      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      2.188      1.962      1.478          4        640: 100%|██████████| 115/115 [19:49<00:00, 10.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.459      0.468      0.462      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      2.188      1.916      1.479          2        640: 100%|██████████| 115/115 [18:32<00:00,  9.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:19<00:00,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.486      0.452      0.441      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 2.336 hours.\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics 8.3.161  Python-3.12.3 torch-2.7.1+cpu CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:18<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203       0.46      0.468      0.462      0.173\n",
      "Speed: 3.4ms preprocess, 129.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001DEB9A03560>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,\n",
       "            0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.81818,     0.80769,\n",
       "            0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,\n",
       "            0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,\n",
       "            0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80769,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,\n",
       "            0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.80645,     0.78788,     0.78788,     0.78788,     0.78788,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,\n",
       "              0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,       0.775,     0.71111,     0.71111,     0.71111,     0.71111,     0.71111,     0.68966,     0.68966,     0.68966,\n",
       "            0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,\n",
       "            0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68966,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,     0.68852,\n",
       "            0.68254,     0.68254,     0.68254,     0.68254,     0.68254,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64789,     0.64474,     0.64474,     0.64474,\n",
       "            0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64474,     0.64103,     0.64103,     0.64103,     0.64103,     0.64103,     0.63415,     0.63415,     0.63415,     0.63415,     0.63415,     0.63415,\n",
       "            0.63415,     0.63415,     0.63415,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,       0.625,     0.62222,     0.62222,     0.62222,     0.62222,     0.62222,\n",
       "            0.60638,     0.60638,     0.60638,     0.60638,     0.60638,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,\n",
       "            0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59615,     0.59434,     0.59434,     0.59434,     0.59434,     0.59434,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,\n",
       "            0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,\n",
       "            0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58871,     0.58594,     0.58594,     0.58594,     0.58594,     0.58594,     0.58594,     0.58594,     0.58594,\n",
       "            0.58594,     0.58594,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,\n",
       "            0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58451,     0.58333,     0.58333,     0.58333,     0.58333,     0.58333,\n",
       "            0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55769,     0.55769,     0.55769,     0.55769,     0.55769,     0.55346,     0.55346,     0.55346,     0.55346,     0.55346,      0.5528,      0.5528,      0.5528,\n",
       "             0.5528,     0.53254,     0.53254,     0.53254,     0.53254,     0.53254,     0.51124,     0.51124,     0.51124,     0.51124,     0.51124,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.48691,     0.47475,     0.47475,\n",
       "            0.47475,     0.47475,     0.47475,     0.46341,     0.46341,     0.46341,     0.46341,     0.46341,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,\n",
       "            0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,     0.44843,      0.4469,      0.4469,      0.4469,      0.4469,      0.4469,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,\n",
       "            0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43933,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.43496,     0.42412,     0.42412,\n",
       "            0.42412,     0.42412,     0.42412,     0.42412,     0.42412,     0.42412,     0.42412,     0.42412,     0.42308,     0.42308,     0.42308,     0.42308,     0.42308,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,      0.4058,\n",
       "            0.40357,     0.40357,     0.40357,     0.40357,     0.40357,     0.40283,     0.40283,     0.40283,     0.40283,     0.40283,      0.4021,      0.4021,      0.4021,      0.4021,     0.40138,     0.40138,     0.40138,     0.40138,     0.40138,     0.39274,     0.39274,     0.39274,     0.39274,\n",
       "            0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.39274,     0.38585,     0.38585,     0.38585,     0.38585,     0.38585,      0.3805,      0.3805,      0.3805,      0.3805,      0.3805,     0.37273,     0.37273,\n",
       "            0.37273,     0.37273,     0.37273,     0.37273,     0.37273,     0.37273,     0.37273,     0.37273,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36337,     0.36103,     0.36103,     0.36103,     0.36103,     0.36103,\n",
       "            0.35876,     0.35876,     0.35876,     0.35876,     0.35854,     0.35854,     0.35854,     0.35854,     0.35854,     0.35734,     0.35734,     0.35734,     0.35734,     0.35734,      0.3523,      0.3523,      0.3523,      0.3523,      0.3523,     0.34921,     0.34921,     0.34921,     0.34921,\n",
       "            0.34921,     0.34921,     0.34921,     0.34921,     0.34921,     0.34921,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34884,     0.34772,     0.34772,\n",
       "            0.34772,     0.34772,     0.34772,     0.34772,     0.34772,     0.34772,     0.34772,     0.34772,     0.34328,     0.34328,     0.34328,     0.34328,     0.34328,     0.33575,     0.33575,     0.33575,     0.33575,     0.33575,     0.33254,     0.33254,     0.33254,     0.33254,     0.33099,\n",
       "            0.33099,     0.33099,     0.33099,     0.33099,     0.32947,     0.32947,     0.32947,     0.32947,     0.32947,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,     0.32438,\n",
       "            0.32438,      0.3223,      0.3223,      0.3223,      0.3223,      0.3223,     0.32096,     0.32096,     0.32096,     0.32096,     0.32096,     0.30266,     0.30266,     0.30266,     0.30266,     0.30266,     0.26847,     0.26847,     0.26847,     0.26847,     0.26847,     0.25685,     0.25685,\n",
       "            0.25685,     0.25685,     0.25685,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,     0.25535,\n",
       "            0.25535,     0.25535,     0.25535,     0.25535,     0.25449,     0.25449,     0.25449,     0.25449,     0.25449,     0.25363,     0.25363,     0.25363,     0.25363,     0.25363,     0.24383,     0.24383,     0.24383,     0.24383,     0.24383,     0.23739,     0.23739,     0.23739,     0.23739,\n",
       "            0.23739,     0.23739,     0.23739,     0.23739,     0.23739,     0.23739,        0.23,        0.23,        0.23,        0.23,        0.23,     0.22721,     0.22721,     0.22721,     0.22721,     0.22721,     0.22702,     0.22702,     0.22702,     0.22702,     0.22702,     0.22297,     0.22297,\n",
       "            0.22297,     0.22297,     0.22297,     0.22297,     0.22297,     0.22297,     0.22297,     0.22222,     0.22222,     0.22222,     0.22222,     0.22222,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.22047,     0.21863,\n",
       "            0.21863,     0.21863,     0.21863,     0.21863,     0.21656,     0.21656,     0.21656,     0.21656,     0.21656,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.21287,     0.20595,     0.20595,     0.20595,     0.20595,\n",
       "            0.20595,     0.20567,     0.20567,     0.20567,     0.20567,     0.20567,      0.2054,      0.2054,      0.2054,      0.2054,      0.2054,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,     0.20252,         0.2,         0.2,\n",
       "                0.2,         0.2,     0.19845,     0.19845,     0.19845,     0.19845,     0.19845,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,     0.19338,       0.193,       0.193,       0.193,       0.193,       0.193,     0.19023,\n",
       "            0.19023,     0.19023,     0.19023,     0.19023,     0.16429,     0.16429,     0.16429,     0.16429,     0.16429,     0.16401,     0.16401,     0.16401,     0.16401,     0.16401,     0.15221,     0.15221,     0.15221,     0.15221,     0.15221,      0.1421,      0.1421,      0.1421,      0.1421,\n",
       "             0.1421,      0.1255,      0.1255,      0.1255,      0.1255,      0.1255,     0.11659,     0.11659,     0.11659,     0.11659,     0.11659,     0.10653,     0.10653,     0.10653,     0.10653,     0.10653,     0.10653,     0.10653,     0.10653,     0.10653,     0.10089,     0.10089,     0.10089,\n",
       "            0.10089,     0.10089,    0.095074,    0.095074,    0.095074,    0.095074,    0.095074,    0.093046,    0.093046,    0.093046,    0.093046,    0.093046,    0.065217,    0.065217,    0.065217,    0.065217,    0.065217,    0.045313,    0.044151,    0.042989,    0.041828,    0.040666,    0.039504,\n",
       "           0.038342,     0.03718,    0.036018,    0.034856,    0.033694,    0.032533,    0.031371,    0.030209,    0.029047,    0.027885,    0.026723,    0.025561,    0.024399,    0.023238,    0.022076,    0.020914,    0.019752,     0.01859,    0.017428,    0.016266,    0.015104,    0.013943,    0.012781,\n",
       "           0.011619,    0.010457,    0.009295,   0.0081331,   0.0069713,   0.0058094,   0.0046475,   0.0034856,   0.0023238,   0.0011619,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.087326,    0.087503,      0.1377,     0.16287,     0.17785,     0.18977,     0.20163,      0.2108,     0.22088,     0.22736,     0.23311,     0.23981,     0.24579,     0.25277,     0.25833,     0.26312,     0.26868,     0.27354,     0.27716,     0.28095,     0.28608,     0.29181,     0.29714,\n",
       "            0.30318,      0.3089,     0.31368,       0.317,     0.31824,     0.32337,     0.32553,     0.32659,     0.33149,       0.331,     0.33554,     0.33937,     0.34152,     0.34286,     0.34543,     0.34886,     0.34993,      0.3532,     0.35574,     0.35877,     0.36419,     0.36326,     0.36928,\n",
       "            0.37303,     0.37894,     0.38212,     0.37921,     0.37932,     0.38033,     0.38719,     0.39039,     0.39277,     0.39985,     0.40801,     0.41389,     0.42414,      0.4283,     0.43534,       0.441,      0.4431,     0.44306,     0.44738,      0.4478,     0.44633,     0.45043,     0.45182,\n",
       "            0.45767,     0.45599,     0.45469,     0.45151,     0.45401,     0.45575,     0.45448,     0.45646,     0.45376,     0.45698,     0.45168,     0.45494,     0.45765,     0.46128,     0.45872,     0.46171,     0.46176,     0.46555,     0.46497,     0.46575,      0.4685,     0.46771,     0.46348,\n",
       "            0.46776,     0.47039,     0.46998,     0.46963,     0.46738,     0.46619,     0.46776,     0.46612,     0.46271,     0.46435,     0.46578,      0.4698,     0.47102,     0.47445,     0.47301,     0.47356,     0.47331,     0.47164,     0.47099,     0.47096,     0.46942,     0.46914,      0.4701,\n",
       "            0.47151,     0.47465,     0.47649,     0.47001,     0.47241,     0.47347,     0.47483,     0.47087,     0.46823,      0.4674,      0.4677,     0.46876,     0.46903,      0.4693,     0.46957,     0.47018,     0.46861,     0.46774,     0.46839,     0.46467,     0.46013,     0.45492,     0.45262,\n",
       "            0.45425,     0.45499,      0.4555,     0.45794,     0.46232,     0.46372,     0.46439,     0.46213,     0.46325,     0.46574,     0.46643,     0.46714,     0.46827,     0.46758,     0.46836,     0.46935,     0.47127,     0.47074,     0.46851,     0.46616,     0.46694,     0.46734,     0.46774,\n",
       "            0.46998,     0.47263,     0.47391,     0.47669,     0.47751,     0.47517,     0.47638,     0.47666,     0.47695,     0.47724,     0.47972,      0.4807,     0.48227,     0.48279,     0.48081,     0.48275,      0.4847,     0.48682,     0.48862,     0.48543,     0.48253,     0.48408,     0.48084,\n",
       "             0.4806,     0.47502,     0.47738,     0.47922,     0.48256,     0.48108,     0.48089,     0.47565,     0.47111,     0.46815,     0.46658,     0.46074,     0.45689,     0.45509,     0.45069,     0.44465,     0.44596,     0.43816,     0.43534,     0.43434,     0.42413,     0.42208,     0.41786,\n",
       "            0.41265,      0.4095,     0.40612,     0.40506,     0.40322,     0.39895,     0.38946,     0.38984,     0.39021,     0.39059,     0.38808,      0.3847,     0.38281,     0.38092,     0.38117,     0.38293,     0.38361,     0.38003,     0.37752,     0.37403,     0.36786,     0.36271,     0.36121,\n",
       "            0.35361,     0.35523,     0.35315,     0.35107,     0.35049,     0.33778,     0.33537,     0.32667,     0.32466,     0.32243,     0.32041,     0.31768,     0.29941,     0.29688,     0.29435,     0.28418,      0.2788,     0.27459,     0.27526,     0.26718,     0.26267,     0.25769,     0.25789,\n",
       "            0.25346,     0.25468,     0.24758,     0.24618,     0.24478,     0.24337,     0.24197,      0.2404,      0.2368,     0.23315,     0.22859,     0.22623,     0.22688,     0.22456,      0.2222,     0.21983,     0.22022,     0.20538,     0.20231,     0.19923,     0.18768,     0.18267,     0.18319,\n",
       "            0.18239,     0.18062,     0.17886,     0.17709,      0.1746,     0.16691,     0.16574,     0.16457,      0.1634,     0.16223,     0.16106,     0.15988,     0.15104,     0.14827,      0.1455,     0.14271,     0.13975,     0.13679,     0.13253,     0.12064,     0.11495,     0.11182,      0.1091,\n",
       "            0.10921,     0.10931,     0.10941,     0.10951,     0.10962,     0.10978,     0.10993,     0.11008,     0.10673,     0.10296,    0.095848,    0.091464,     0.08975,    0.088033,    0.086314,    0.084592,    0.084094,    0.075204,    0.072906,    0.070669,    0.068428,    0.066183,    0.054589,\n",
       "           0.050472,    0.046622,    0.043386,    0.040143,    0.038315,    0.038393,     0.03846,    0.036478,    0.034451,    0.032421,    0.030388,    0.028749,     0.02799,     0.02723,     0.02647,    0.025709,    0.024948,    0.024187,    0.023425,    0.022663,      0.0219,    0.021137,    0.020373,\n",
       "           0.019609,     0.01312,   0.0097577,   0.0097602,   0.0097626,   0.0097648,    0.009767,    0.009769,    0.009771,   0.0097728,   0.0097746,   0.0097763,   0.0097779,   0.0097795,    0.009781,   0.0097824,   0.0097838,   0.0097851,   0.0097864,   0.0097876,   0.0097888,   0.0097899,    0.009791,\n",
       "          0.0097921,   0.0097931,   0.0097941,   0.0097951,    0.009796,   0.0097969,   0.0097977,   0.0097986,   0.0097994,   0.0098002,    0.009801,   0.0098017,   0.0098024,   0.0098031,   0.0098038,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.045742,     0.04584,    0.074195,    0.089019,    0.098156,     0.10565,     0.11306,     0.11894,     0.12541,     0.12968,     0.13344,     0.13785,     0.14193,     0.14661,     0.15036,     0.15375,     0.15757,     0.16092,     0.16359,     0.16641,     0.17002,     0.17408,     0.17789,\n",
       "            0.18223,     0.18638,     0.18987,     0.19277,     0.19416,     0.19799,     0.20012,     0.20146,     0.20524,     0.20567,     0.20919,     0.21217,      0.2145,      0.2158,     0.21827,     0.22173,     0.22371,     0.22678,     0.22929,     0.23224,     0.23681,     0.23692,     0.24206,\n",
       "            0.24579,     0.25095,     0.25434,     0.25372,     0.25457,     0.25667,     0.26295,     0.26591,     0.26878,     0.27546,     0.28327,     0.28897,     0.29907,     0.30407,     0.31122,     0.31704,     0.32117,     0.32331,     0.32885,      0.3304,     0.33106,     0.33559,     0.33835,\n",
       "            0.34624,     0.34694,     0.34815,     0.34867,     0.35316,     0.35624,     0.35686,     0.36099,     0.35922,      0.3633,     0.35985,     0.36419,     0.36768,     0.37256,     0.37282,     0.37678,     0.37869,     0.38398,     0.38529,     0.38635,     0.39017,     0.39098,     0.38983,\n",
       "            0.39593,     0.39971,     0.40034,     0.40106,     0.40024,     0.40102,     0.40335,     0.40351,     0.40247,     0.40624,     0.40842,     0.41464,     0.41655,     0.42196,     0.42267,     0.42356,     0.42372,     0.42259,     0.42252,     0.42309,     0.42204,     0.42267,     0.42423,\n",
       "            0.42653,      0.4317,     0.43475,     0.43047,     0.43472,     0.43653,     0.43914,     0.43644,     0.43463,     0.43743,     0.44124,     0.44313,     0.44361,      0.4441,     0.44459,     0.44568,     0.44535,     0.44526,     0.44645,     0.44511,     0.44321,     0.43957,     0.43823,\n",
       "            0.44131,      0.4427,     0.44366,     0.44832,      0.4568,     0.45954,     0.46251,     0.46093,     0.46344,     0.46845,     0.46985,      0.4713,      0.4736,     0.47743,     0.47906,     0.48113,     0.48518,     0.48598,     0.48489,     0.48552,     0.48723,      0.4881,     0.48898,\n",
       "             0.4939,     0.49979,     0.50266,     0.50895,     0.51111,     0.51192,     0.51472,     0.51539,     0.51607,     0.51674,      0.5226,     0.52492,     0.52869,     0.53181,     0.53226,     0.53705,     0.54191,     0.54724,     0.55179,      0.5515,     0.55203,      0.5561,     0.55589,\n",
       "            0.55763,     0.55752,     0.56407,     0.56923,     0.57874,     0.58129,     0.58372,     0.58082,     0.57776,     0.57575,     0.57792,     0.57391,     0.57438,     0.58015,     0.58421,     0.58237,     0.58691,     0.58285,     0.58469,     0.58792,     0.58056,     0.58528,     0.58417,\n",
       "            0.58032,     0.58406,     0.58738,     0.59231,     0.59564,     0.59242,      0.5901,     0.59183,     0.59357,     0.59531,     0.59392,      0.5913,     0.58982,     0.58835,     0.59328,     0.60187,     0.60526,     0.61059,     0.62236,     0.62193,     0.62238,     0.62106,     0.63124,\n",
       "            0.62659,     0.64052,     0.63886,     0.63721,     0.63961,     0.63383,     0.64492,     0.64033,     0.64655,     0.67481,     0.68019,     0.68387,     0.68371,     0.68153,     0.67935,     0.67032,       0.677,     0.67315,     0.68223,     0.67848,     0.68377,     0.68247,     0.70845,\n",
       "            0.74494,      0.7665,     0.76893,     0.76776,     0.76659,     0.76542,     0.76424,     0.76293,     0.75978,     0.75659,     0.75241,      0.7563,     0.77123,     0.76933,     0.76721,     0.76508,     0.78777,     0.79943,     0.79669,     0.79395,     0.78289,     0.77995,     0.79946,\n",
       "            0.80671,       0.805,     0.80329,     0.80159,     0.79912,     0.79112,     0.78981,      0.7885,     0.78719,     0.78588,     0.78457,     0.78327,     0.77263,       0.769,     0.76536,     0.76169,     0.75746,     0.75323,     0.74686,     0.72738,     0.71706,     0.71109,     0.70702,\n",
       "            0.71592,     0.72482,     0.73372,     0.74262,     0.75261,     0.76787,     0.78313,     0.79839,     0.79447,      0.7883,     0.77532,     0.76678,     0.76305,     0.75933,     0.75561,     0.75188,     0.81476,     0.80017,     0.79457,     0.78909,     0.78361,     0.77813,     0.74116,\n",
       "            0.72527,     0.70919,     0.69267,     0.67615,     0.68988,      0.7444,     0.79893,      0.7895,     0.77879,     0.76809,     0.75738,     0.74794,      0.7413,     0.73467,     0.72804,      0.7214,     0.71477,     0.70813,      0.7015,     0.69487,     0.68823,      0.6816,     0.67497,\n",
       "            0.66833,     0.55791,     0.50841,      0.5224,     0.53638,     0.55037,     0.56436,     0.57834,     0.59233,     0.60632,     0.62031,     0.63429,     0.64828,     0.66227,     0.67625,     0.69024,     0.70423,     0.71821,      0.7322,     0.74619,     0.76018,     0.77416,     0.78815,\n",
       "            0.80214,     0.81612,     0.83011,      0.8441,     0.85809,     0.87207,     0.88606,     0.90005,     0.91403,     0.92802,     0.94201,       0.956,     0.96998,     0.98397,     0.99796,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96059,     0.96059,     0.95567,     0.95567,     0.94581,     0.93103,     0.93103,     0.92611,      0.9253,     0.92118,     0.92118,     0.92118,     0.91626,     0.91626,     0.91626,     0.91133,     0.91133,     0.91133,      0.9064,     0.90148,     0.90148,     0.90148,     0.90148,\n",
       "            0.90148,     0.90148,     0.90148,     0.89163,     0.88177,     0.88177,     0.87192,     0.86207,     0.86125,     0.84729,     0.84729,     0.84729,     0.83744,      0.8337,     0.82759,     0.81773,     0.80296,     0.79803,      0.7931,     0.78818,     0.78818,     0.77833,     0.77833,\n",
       "             0.7734,      0.7734,      0.7679,      0.7503,     0.74384,     0.73399,     0.73399,     0.73399,     0.72906,     0.72906,     0.72906,     0.72906,     0.72906,     0.72414,     0.72414,     0.72414,     0.71429,     0.70371,     0.69951,     0.69458,     0.68473,     0.68473,      0.6798,\n",
       "            0.67488,     0.66502,     0.65517,     0.64039,     0.63547,     0.63242,     0.62562,     0.62058,     0.61584,     0.61576,     0.60643,     0.60591,     0.60591,     0.60547,     0.59606,     0.59606,      0.5915,     0.59113,     0.58621,     0.58621,     0.58621,      0.5819,     0.57143,\n",
       "            0.57143,     0.57143,     0.56895,      0.5665,     0.56158,     0.55665,     0.55665,     0.55172,     0.54416,     0.54187,     0.54187,     0.54187,     0.54187,     0.54187,     0.53695,     0.53695,     0.53606,     0.53358,     0.53202,     0.53106,     0.52878,     0.52709,     0.52709,\n",
       "            0.52709,     0.52709,     0.52709,     0.51754,     0.51724,     0.51724,     0.51684,      0.5112,     0.50746,     0.50178,     0.49754,     0.49754,     0.49754,     0.49754,     0.49754,     0.49754,     0.49443,     0.49261,     0.49261,     0.48604,     0.47839,     0.47138,     0.46798,\n",
       "            0.46798,     0.46798,     0.46798,     0.46798,     0.46798,     0.46798,     0.46629,     0.46333,     0.46305,     0.46305,     0.46305,     0.46305,     0.46305,     0.45813,     0.45813,     0.45813,     0.45813,     0.45642,      0.4532,     0.44828,     0.44828,     0.44828,     0.44828,\n",
       "            0.44828,     0.44828,     0.44828,     0.44828,     0.44805,     0.44335,     0.44335,     0.44335,     0.44335,     0.44335,     0.44335,     0.44335,     0.44335,     0.44204,     0.43842,     0.43842,     0.43842,     0.43842,     0.43842,      0.4335,     0.42857,     0.42857,     0.42365,\n",
       "            0.42227,     0.41379,     0.41379,     0.41379,     0.41379,     0.41034,     0.40887,     0.40272,     0.39769,     0.39444,     0.39122,     0.38485,     0.37931,     0.37438,     0.36685,     0.35961,     0.35961,     0.35103,     0.34677,     0.34438,     0.33411,     0.33005,     0.32526,\n",
       "            0.32014,     0.31527,     0.31034,     0.30776,     0.30477,     0.30073,     0.29064,     0.29064,     0.29064,     0.29064,      0.2882,     0.28508,     0.28336,     0.28163,     0.28079,     0.28079,     0.28079,     0.27586,     0.27094,     0.26743,     0.26108,     0.25616,     0.25299,\n",
       "            0.24631,     0.24577,     0.24402,     0.24228,     0.24138,     0.23024,      0.2266,     0.21927,     0.21675,     0.21182,     0.20957,      0.2069,     0.19168,     0.18978,     0.18788,     0.18031,     0.17554,     0.17247,     0.17241,     0.16634,     0.16256,     0.15883,     0.15764,\n",
       "            0.15271,     0.15271,     0.14754,     0.14659,     0.14564,     0.14469,     0.14374,     0.14268,     0.14026,     0.13781,     0.13476,       0.133,       0.133,     0.13147,     0.12991,     0.12835,       0.128,     0.11782,     0.11587,     0.11391,     0.10662,     0.10345,     0.10345,\n",
       "            0.10282,     0.10172,     0.10063,     0.09954,    0.098004,    0.093297,    0.092586,    0.091874,    0.091162,    0.090451,    0.089739,    0.089027,    0.083701,    0.082045,    0.080389,    0.078728,    0.076978,    0.075228,    0.072715,    0.065777,    0.062482,    0.060683,    0.059113,\n",
       "           0.059113,    0.059113,    0.059113,    0.059113,    0.059113,    0.059113,    0.059113,    0.059113,    0.057208,    0.055077,    0.051081,    0.048633,    0.047679,    0.046725,    0.045771,    0.044817,    0.044335,    0.039456,    0.038206,    0.036991,    0.035776,    0.034562,    0.028338,\n",
       "           0.026146,    0.024103,    0.022394,    0.020686,    0.019704,    0.019704,    0.019704,     0.01867,    0.017615,     0.01656,    0.015505,    0.014656,    0.014264,    0.013872,     0.01348,    0.013088,    0.012696,    0.012304,    0.011911,    0.011519,    0.011127,    0.010735,    0.010343,\n",
       "          0.0099507,   0.0066378,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,\n",
       "          0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,   0.0049261,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.20197219983572356\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.17312])\n",
       "names: {0: 'traffic_sign'}\n",
       "nt_per_class: array([203], dtype=int64)\n",
       "nt_per_image: array([120], dtype=int64)\n",
       "results_dict: {'metrics/precision(B)': 0.45954045070271704, 'metrics/recall(B)': 0.46798029556650245, 'metrics/mAP50(B)': 0.4616676248061544, 'metrics/mAP50-95(B)': 0.1731171526167868, 'fitness': 0.20197219983572356}\n",
       "save_dir: WindowsPath('runs/detect/train10')\n",
       "speed: {'preprocess': 3.4011008334346116, 'inference': 129.39444583607838, 'loss': 0.00010500079952180386, 'postprocess': 1.8880799994803965}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data=r'C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\tsdd.yaml', epochs=10, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e410f0-bb36-4cbf-ae84-baacc6ec5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.161  Python-3.12.3 torch-2.7.1+cpu CPU (12th Gen Intel Core(TM) i5-12500H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\tsdd.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\aswin\\jupyter_codes\\runs\\detect\\train10\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train12, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 705.0387.8 MB/s, size: 960.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\train.cache... 1403 images, 468 backgrounds, 44 corrupt: 100%|██████████| 1871/1871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd (34).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.2086      3.2854      3.4383      3.2854      3.7391      3.2635]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd (36).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.9742      1.6073]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1000.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4719      1.3844]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1003.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.7984      1.1323]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1011.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1352      1.5615      1.6383      1.5208      2.1172      1.4865      2.5766      1.4937      3.0734      1.4531]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1016.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.3164      1.0646      2.6813      1.1594      2.0328      1.2958      1.2961      1.4792      1.6156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1017.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2177      3.4594      1.7687      2.6609      1.5542       2.007      1.4427      1.3703      1.2271]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1021.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7602      1.8708      2.0719       1.874      2.1969      1.8469]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1025.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5969      1.3906      2.1656      1.2177      2.5812      1.0917]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_1027.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5945      1.5042      2.2172      1.6354         2.6       1.749]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_202.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2609]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_646.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1914      2.2039      1.6771      2.2297      2.6156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_660.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.6172      1.7656]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_661.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1914      1.6635      1.5672]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_667.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4414      1.8979      2.0867      1.8135      2.7477       1.799      3.4562      1.7615]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_677.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4898      2.0135]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_678.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1172      1.8292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_681.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2578      1.6938      2.3031      1.9594       2.275      2.2385]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_687.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9922      1.6844      2.0586       2.249       2.018      1.1625]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_689.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.043      1.0646      2.1195       1.599       2.207      2.0583]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_691.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0766       1.401      2.1047      1.6802]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_696.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.018      1.3365      2.0641      2.3021      1.0958]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_704.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0586       1.575      1.1208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_730.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0664      1.5229      2.0234      1.8135      1.9875      2.0844]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_749.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9289      2.9562]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_755.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1937      1.4552      2.1883      1.6771      2.1633      1.8479]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_802.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9727      1.3229      1.9469        1.85]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_806.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0047      1.5104      2.0531      2.0885]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_836.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.525      2.7823]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_845.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.3625      2.0271      2.3805      2.1865]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_848.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5766      2.7344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_853.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5719      2.5302      2.5812      2.7552      2.6273      3.0448]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_858.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.5055      3.1021      2.5102      3.2344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_885.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.4867       1.976      1.8547      1.9865      2.1984      1.9323]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_888.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.5203      1.5781      1.9469      1.4688      2.2578      1.3292]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_898.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.6664      2.8031      1.8898      1.6562]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_957.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.4156      2.2938      1.7135      2.1477      2.4896]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_958.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.9156      2.0586       1.551      2.2422      2.3198]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_961.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.1039      1.5604       2.143      1.8094      2.1883      2.0708]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_964.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2297      1.6531]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_986.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.7039      1.8708      1.8953      1.8062      2.0508       1.775      2.2445      1.7271]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_993.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0617      1.4312      2.0766      1.7083       2.082       1.976]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_994.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.2445      1.5812      2.1992      1.8094      2.2195      2.1156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\train\\tsd_995.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.0539      1.4698      2.1195      1.7687      2.1578      2.0135]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 531.5152.8 MB/s, size: 137.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\aswin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\labels\\val.cache... 122 images, 0 backgrounds, 2 corrupt: 100%|██████████| 122/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\val\\tsd (33).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     3.2008      3.6531]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\images\\val\\tsd (35).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     2.7891      4.0146      3.0109      3.9875      3.2133      4.0583]\n",
      "Plotting labels to runs\\detect\\train12\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\aswin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train12\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      2.269      2.027      1.478          4        640: 100%|██████████| 115/115 [19:39<00:00, 10.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:14<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.503      0.424      0.457       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G      2.217      1.994      1.465          3        640: 100%|██████████| 115/115 [19:10<00:00, 10.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:17<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        120        203      0.393      0.433       0.31      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G      2.176      1.958      1.499         48        640:   5%|▌         | 6/115 [00:56<16:59,  9.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maswin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjupyter_codes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain10\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlast.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# or use best.pt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Start new training from that point\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maswin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjupyter_codes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtsdd_yolo_dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtsdd.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\model.py:799\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:406\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m    405\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 406\u001b[0m     loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:137\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:336\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m--> 336\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:156\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:179\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 179\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    180\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:80\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your finished model as the starting point\n",
    "model = YOLO(r\"C:\\Users\\aswin\\jupyter_codes\\runs\\detect\\train10\\weights\\last.pt\")  # or use best.pt\n",
    "\n",
    "# Start new training from that point\n",
    "model.train(data=r'C:\\Users\\aswin\\jupyter_codes\\tsdd_yolo_dataset\\tsdd.yaml', epochs=5)  # This means 5 NEW epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6dfbc-3524-4ab2-84ba-dc675a976a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
